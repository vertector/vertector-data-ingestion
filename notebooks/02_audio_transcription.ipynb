{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Transcription with Vertector\n",
    "\n",
    "Demonstrates:\n",
    "- Whisper model configuration\n",
    "- MLX vs Standard backend\n",
    "- Timestamped transcriptions\n",
    "- Multi-language support\n",
    "- Batch processing\n",
    "- SRT generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-02 19:00:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.monitoring.logger\u001b[0m:\u001b[36msetup_logging\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mLogging initialized at INFO level\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from vertector_data_ingestion import (\n",
    "    create_audio_transcriber,\n",
    "    AudioConfig,\n",
    "    WhisperModelSize,\n",
    "    AudioBackend,\n",
    "    HardwareDetector,\n",
    "    setup_logging,\n",
    ")\n",
    "\n",
    "setup_logging(log_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-02 19:02:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.hardware_detector\u001b[0m:\u001b[36mdetect\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDetected Apple Silicon with MPS support\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardware:\n",
      "  Device: mps\n",
      "  Chip: M1\n",
      "  Use MLX: True\n",
      "  Batch Size: 8\n",
      "\n",
      "✓ Recommend: MLX backend (10-20x faster on Apple Silicon)\n"
     ]
    }
   ],
   "source": [
    "hw_info = HardwareDetector.get_device_info()\n",
    "\n",
    "print(\"Hardware:\")\n",
    "print(f\"  Device: {hw_info.get('device_type')}\")\n",
    "print(f\"  Chip: {hw_info.get('chip', 'Unknown')}\")\n",
    "print(f\"  Use MLX: {hw_info.get('use_mlx', False)}\")\n",
    "print(f\"  Batch Size: {hw_info.get('batch_size', 1)}\")\n",
    "\n",
    "if hw_info.get('device_type') == 'mps':\n",
    "    print(\"\\n✓ Recommend: MLX backend (10-20x faster on Apple Silicon)\")\n",
    "elif hw_info.get('device_type') == 'cuda':\n",
    "    print(\"\\n✓ Recommend: Standard with CUDA\")\n",
    "else:\n",
    "    print(\"\\n✓ Recommend: Standard (CPU)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-02 19:02:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.audio_factory\u001b[0m:\u001b[36mcreate_audio_transcriber\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCreating audio transcriber: model=base, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.hardware_detector\u001b[0m:\u001b[36mdetect\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDetected Apple Silicon with MPS support\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mInitializing WhisperTranscriber with model=base, device=mlx, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mLoading Whisper model: base\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mLoaded MLX Whisper model: base\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mTranscribing harvard.wav with mlx backend\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c33ab99161843b9b491aebbd624504c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-02 19:02:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mTranscription complete in 6.37s: 216 chars, 6 segments\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "  Text: The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health and zest. A salt pickle tastes fine with ham. Tacos al pastor are my favorite. A zestful food is the hot cross bun.\n",
      "  Language: en\n",
      "  Duration: 6.37s\n",
      "  Segments: 6\n"
     ]
    }
   ],
   "source": [
    "config = AudioConfig(\n",
    "    model_size=WhisperModelSize.BASE,\n",
    "    backend=AudioBackend.AUTO,\n",
    "    language=\"en\",\n",
    "    word_timestamps=True,\n",
    ")\n",
    "\n",
    "transcriber = create_audio_transcriber(config)\n",
    "audio_path = Path(\"../test_documents/harvard.wav\")\n",
    "\n",
    "if audio_path.exists():\n",
    "    result = transcriber.transcribe(audio_path)\n",
    "    \n",
    "    print(\"Result:\")\n",
    "    print(f\"  Text: {result.text}\")\n",
    "    print(f\"  Language: {result.language}\")\n",
    "    print(f\"  Duration: {result.duration:.2f}s\")\n",
    "    print(f\"  Segments: {len(result.segments)}\")\n",
    "else:\n",
    "    print(f\"File not found: {audio_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamped Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Segment 1:\n",
      "  Time: [0.9s - 3.6s]\n",
      "  Text: The stale smell of old beer lingers.\n",
      "\n",
      "Segment 2:\n",
      "  Time: [4.2s - 6.2s]\n",
      "  Text: It takes heat to bring out the odor.\n",
      "\n",
      "Segment 3:\n",
      "  Time: [7.0s - 9.2s]\n",
      "  Text: A cold dip restores health and zest.\n",
      "\n",
      "Segment 4:\n",
      "  Time: [10.0s - 12.0s]\n",
      "  Text: A salt pickle tastes fine with ham.\n",
      "\n",
      "Segment 5:\n",
      "  Time: [12.7s - 14.3s]\n",
      "  Text: Tacos al pastor are my favorite.\n"
     ]
    }
   ],
   "source": [
    "if audio_path.exists():\n",
    "    for i, segment in enumerate(result.segments[:5], 1):\n",
    "        print(f\"\\nSegment {i}:\")\n",
    "        print(f\"  Time: [{segment.start:.1f}s - {segment.end:.1f}s]\")\n",
    "        print(f\"  Text: {segment.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Size Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-02 19:02:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.audio_factory\u001b[0m:\u001b[36mcreate_audio_transcriber\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCreating audio transcriber: model=tiny, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.hardware_detector\u001b[0m:\u001b[36mdetect\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDetected Apple Silicon with MPS support\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mInitializing WhisperTranscriber with model=tiny, device=mlx, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mLoading Whisper model: tiny\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mLoaded MLX Whisper model: tiny\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mTranscribing harvard.wav with mlx backend\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b96fcd9770f47c8b88e79c2e2ed4be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-02 19:02:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mTranscription complete in 1.04s: 219 chars, 6 segments\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.audio_factory\u001b[0m:\u001b[36mcreate_audio_transcriber\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCreating audio transcriber: model=base, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.hardware_detector\u001b[0m:\u001b[36mdetect\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDetected Apple Silicon with MPS support\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mInitializing WhisperTranscriber with model=base, device=mlx, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mLoading Whisper model: base\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mLoaded MLX Whisper model: base\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mTranscribing harvard.wav with mlx backend\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TINY: 1.05s\n",
      "  Text: The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d287f6a7fea49cea0af5f21af9792b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-02 19:02:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mTranscription complete in 1.27s: 216 chars, 6 segments\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.audio_factory\u001b[0m:\u001b[36mcreate_audio_transcriber\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCreating audio transcriber: model=small, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.hardware_detector\u001b[0m:\u001b[36mdetect\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDetected Apple Silicon with MPS support\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mInitializing WhisperTranscriber with model=small, device=mlx, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mLoading Whisper model: small\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mLoaded MLX Whisper model: small\u001b[0m\n",
      "\u001b[32m2026-01-02 19:02:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mTranscribing harvard.wav with mlx backend\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BASE: 1.27s\n",
      "  Text: The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1de82296414a97b351c1a83ca2d706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-02 19:02:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mTranscription complete in 3.29s: 216 chars, 6 segments\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SMALL: 3.30s\n",
      "  Text: The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "if audio_path.exists():\n",
    "    models = [WhisperModelSize.TINY, WhisperModelSize.BASE, WhisperModelSize.SMALL]\n",
    "    \n",
    "    print(\"Model Comparison:\")\n",
    "    for model_size in models:\n",
    "        config = AudioConfig(model_size=model_size, backend=AudioBackend.AUTO)\n",
    "        transcriber = create_audio_transcriber(config)\n",
    "        \n",
    "        start = time.time()\n",
    "        result = transcriber.transcribe(audio_path)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        print(f\"\\n{model_size.value.upper()}: {elapsed:.2f}s\")\n",
    "        print(f\"  Text: {result.text[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-02 19:04:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.audio_factory\u001b[0m:\u001b[36mcreate_audio_transcriber\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCreating audio transcriber: model=base, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.hardware_detector\u001b[0m:\u001b[36mdetect\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDetected Apple Silicon with MPS support\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mInitializing WhisperTranscriber with model=base, device=mlx, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mLoading Whisper model: base\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mLoaded MLX Whisper model: base\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mTranscribing harvard.wav with mlx backend\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31efe56a88f42c981744c09ac6daf6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-02 19:04:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mTranscription complete in 2.13s: 216 chars, 6 segments\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n",
      "Text: The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health and zest. A salt pickle tastes fine with ham. Tacos al pastor are my favorite. A zestful food is th...\n"
     ]
    }
   ],
   "source": [
    "if audio_path.exists():\n",
    "    # Auto-detect\n",
    "    auto_config = AudioConfig(model_size=WhisperModelSize.BASE, language=None)\n",
    "    transcriber = create_audio_transcriber(auto_config)\n",
    "    result = transcriber.transcribe(audio_path)\n",
    "    \n",
    "    print(f\"Detected language: {result.language}\")\n",
    "    print(f\"Text: {result.text[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-02 19:04:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.audio_factory\u001b[0m:\u001b[36mcreate_audio_transcriber\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCreating audio transcriber: model=base, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.hardware_detector\u001b[0m:\u001b[36mdetect\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDetected Apple Silicon with MPS support\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mInitializing WhisperTranscriber with model=base, device=mlx, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mLoading Whisper model: base\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mLoaded MLX Whisper model: base\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mTranscribing harvard.wav with mlx backend\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mTranscription complete in 0.68s: 216 chars, 6 segments\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "harvard.wav: 0.7s\n",
      "  The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health...\n"
     ]
    }
   ],
   "source": [
    "audio_dir = Path(\"../test_documents/\")\n",
    "\n",
    "if audio_dir.exists():\n",
    "    audio_files = list(audio_dir.glob(\"*.wav\")) + list(audio_dir.glob(\"*.mp3\"))\n",
    "    \n",
    "    if audio_files:\n",
    "        config = AudioConfig(model_size=WhisperModelSize.BASE)\n",
    "        transcriber = create_audio_transcriber(config)\n",
    "        \n",
    "        for audio_file in audio_files[:5]:\n",
    "            result = transcriber.transcribe(audio_file)\n",
    "            print(f\"\\n{audio_file.name}: {result.duration:.1f}s\")\n",
    "            print(f\"  {result.text[:100]}...\")\n",
    "else:\n",
    "    print(\"Create '../test_documents/' directory with audio files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate SRT Subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-02 19:04:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.audio_factory\u001b[0m:\u001b[36mcreate_audio_transcriber\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCreating audio transcriber: model=base, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.hardware_detector\u001b[0m:\u001b[36mdetect\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDetected Apple Silicon with MPS support\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mInitializing WhisperTranscriber with model=base, device=mlx, backend=auto\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mLoading Whisper model: base\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36m_load_model\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mLoaded MLX Whisper model: base\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mTranscribing harvard.wav with mlx backend\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.audio.whisper_transcriber\u001b[0m:\u001b[36mtranscribe\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mTranscription complete in 1.16s: 216 chars, 6 segments\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.hardware_detector\u001b[0m:\u001b[36mdetect\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDetected Apple Silicon with MPS support\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.hardware_detector\u001b[0m:\u001b[36mdetect\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDetected Apple Silicon with MPS support\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.pipeline_router\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mHardware detected: mps\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.universal_converter\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mInitialized UniversalConverter on mps\u001b[0m\n",
      "\u001b[32m2026-01-02 19:04:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.universal_converter\u001b[0m:\u001b[36m_ensure_models_available\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mChecking model availability...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: output/transcript.srt\n"
     ]
    }
   ],
   "source": [
    "def format_srt_timestamp(seconds: float) -> str:\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = int(seconds % 60)\n",
    "    millis = int((seconds % 1) * 1000)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}\"\n",
    "\n",
    "if audio_path.exists():\n",
    "    config = AudioConfig(model_size=WhisperModelSize.BASE, word_timestamps=True)\n",
    "    transcriber = create_audio_transcriber(config)\n",
    "    result = transcriber.transcribe(audio_path)\n",
    "    \n",
    "    # Generate SRT\n",
    "    srt_output = []\n",
    "    for i, segment in enumerate(result.segments, 1):\n",
    "        start = format_srt_timestamp(segment.start)\n",
    "        end = format_srt_timestamp(segment.end)\n",
    "        srt_output.append(f\"{i}\\n{start} --> {end}\\n{segment.text.strip()}\\n\")\n",
    "    \n",
    "    srt_content = \"\\n\".join(srt_output)\n",
    "    \n",
    "    # Save using convert_and_export pattern\n",
    "    from vertector_data_ingestion import UniversalConverter\n",
    "    converter = UniversalConverter()\n",
    "    srt_path = converter.config.output_dir / \"transcript.srt\"\n",
    "    srt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    srt_path.write_text(srt_content, encoding=\"utf-8\")\n",
    "    \n",
    "    print(f\"Saved to: {srt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Demonstrated:\n",
    "- Hardware detection\n",
    "- Basic transcription\n",
    "- Timestamped segments\n",
    "- Model comparison\n",
    "- Multi-language support\n",
    "- Batch processing\n",
    "- SRT generation\n",
    "\n",
    "Next: `03_rag_pipeline.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
