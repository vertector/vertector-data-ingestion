{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Processing with Vertector\n",
    "\n",
    "This notebook demonstrates document processing capabilities including:\n",
    "- PDF, DOCX, PPTX, XLSX processing\n",
    "- Classic vs VLM pipeline selection\n",
    "- Export to multiple formats\n",
    "- Table extraction\n",
    "- OCR configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-15 02:40:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.monitoring.logger\u001b[0m:\u001b[36msetup_logging\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mLogging initialized at INFO level\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from vertector_data_ingestion import (\n",
    "    UniversalConverter,\n",
    "    LocalMpsConfig,\n",
    "    CloudGpuConfig,\n",
    "    CloudCpuConfig,\n",
    "    ExportFormat,\n",
    "    PipelineType,\n",
    "    HardwareDetector,\n",
    "    setup_logging,\n",
    ")\n",
    "\n",
    "# Setup logging\n",
    "setup_logging(log_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Detection\n",
    "\n",
    "First, let's detect available hardware to optimize our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-15 02:40:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.hardware_detector\u001b[0m:\u001b[36mdetect\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDetected Apple Silicon with MPS support\u001b[0m\n",
      "\u001b[32m2026-01-15 02:40:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvertector_data_ingestion.core.hardware_detector\u001b[0m:\u001b[36mdetect\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDetected Apple Silicon with MPS support\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardware Information:\n",
      "==================================================\n",
      "device_type: mps\n",
      "batch_size: 8\n",
      "use_fp16: False\n",
      "num_workers: 4\n",
      "use_mlx: True\n",
      "platform: darwin\n",
      "chip: M1\n",
      "\n",
      "Recommended device: HardwareType.MPS\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware\n",
    "hw_info = HardwareDetector.get_device_info()\n",
    "\n",
    "print(\"Hardware Information:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in hw_info.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Get optimized config\n",
    "hw_config = HardwareDetector.detect()\n",
    "print(f\"\\nRecommended device: {hw_config.device_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Document Conversion\n",
    "\n",
    "Convert a document using default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize converter with hardware-optimized config\n",
    "config = LocalMpsConfig()  # or CloudGpuConfig() or CloudCpuConfig()\n",
    "converter = UniversalConverter(config)\n",
    "\n",
    "# Convert a document (replace with your file)\n",
    "# Note: For audio files (.wav, .mp3), install the 'asr' extra: uv sync --extra asr\n",
    "doc_path = Path(\"../test_documents/sample1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doc_path.exists():\n",
    "    # Use unified convert() method\n",
    "    doc = converter.convert(doc_path)\n",
    "    \n",
    "    print(f\"Document: {doc.metadata.source_path.name}\")\n",
    "    print(f\"Pages: {doc.metadata.num_pages}\")\n",
    "    print(f\"Pipeline: {doc.metadata.pipeline_type}\")\n",
    "    print(f\"Processing time: {doc.metadata.processing_time:.2f}s\")\n",
    "else:\n",
    "    print(f\"File not found: {doc_path}\")\n",
    "    print(\"\\nReplace with path to your PDF, DOCX, PPTX, or other document.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Different Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doc_path.exists():\n",
    "    # Export to Markdown\n",
    "    markdown = converter.export(doc, ExportFormat.MARKDOWN)\n",
    "    print(\"Markdown Output (first 500 chars):\")\n",
    "    print(\"=\" * 50)\n",
    "    print(markdown[:500])\n",
    "    print(\"...\\n\")\n",
    "    \n",
    "    # Save to file - output_dir is automatically managed\n",
    "    output_path = converter.convert_and_export(\n",
    "        source=doc_path,\n",
    "        output_name=\"prompt.md\",\n",
    "        format=ExportFormat.MARKDOWN\n",
    "    )\n",
    "    print(f\"Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Selection\n",
    "\n",
    "Compare Classic vs VLM pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if doc_path.exists():\n",
    "    print(\"Classic Pipeline:\")\n",
    "    start = time.time()\n",
    "    classic_doc = converter.convert(doc_path, use_vlm=False)\n",
    "    classic_time = time.time() - start\n",
    "    print(f\"  Time: {classic_time:.2f}s\")\n",
    "    \n",
    "    print(\"\\nVLM Pipeline:\")\n",
    "    start = time.time()\n",
    "    vlm_doc = converter.convert(doc_path, use_vlm=True)\n",
    "    vlm_time = time.time() - start\n",
    "    print(f\"  Time: {vlm_time:.2f}s\")\n",
    "    print(f\"\\nVLM is {vlm_time/classic_time:.2f}x slower (but more accurate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing\n",
    "\n",
    "Process multiple documents with the same unified API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_dir = Path(\"../test_documents/\")\n",
    "\n",
    "if documents_dir.exists():\n",
    "    pdf_files = list(documents_dir.glob(\"*.pdf\"))[:5]\n",
    "    \n",
    "    if pdf_files:\n",
    "        print(f\"Processing {len(pdf_files)} documents...\")\n",
    "        \n",
    "        # Same convert() method - just pass a list!\n",
    "        results = converter.convert(pdf_files, parallel=True)\n",
    "        \n",
    "        print(\"\\nResults:\")\n",
    "        for doc in results:\n",
    "            print(f\"  {doc.metadata.source_path.name}: {doc.metadata.num_pages} pages\")\n",
    "    else:\n",
    "        print(\"No PDF files found\")\n",
    "else:\n",
    "    print(\"Create a 'documents/' directory with PDFs to test batch processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Unified `convert()` API for single and batch processing\n",
    "- Hardware detection\n",
    "- Pipeline selection\n",
    "- Export capabilities\n",
    "\n",
    "Next: Check out `02_audio_transcription.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
